import os
import pickle
import json
import concurrent.futures
from typing import List, Dict
from googleapiclient.discovery import build
from google.oauth2 import service_account
from google.auth.transport.requests import Request
from googleapiclient.http import MediaFileUpload, MediaIoBaseDownload
from google_auth_oauthlib.flow import InstalledAppFlow

SCOPES = ["https://www.googleapis.com/auth/drive"]

# --- C√ÅC H√ÄM X√ÅC TH·ª∞C V√Ä TI·ªÜN √çCH GI·ªÆ NGUY√äN ---
def authenticate_oauth(client_secret_path, token_pickle, scopes=SCOPES):
    creds = None
    if os.path.exists(token_pickle):
        with open(token_pickle, "rb") as f:
            creds = pickle.load(f)
    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
        else:
            flow = InstalledAppFlow.from_client_secrets_file(client_secret_path, scopes)
            creds = flow.run_local_server(port=0)
        with open(token_pickle, "wb") as f:
            pickle.dump(creds, f)
    return build("drive", "v3", credentials=creds)

def authenticate_sa(credentials_file: str):
    credentials = service_account.Credentials.from_service_account_file(credentials_file, scopes=SCOPES)
    return build('drive', 'v3', credentials=credentials)

def extract_folder_id(link_or_id: str) -> str:
    import re
    m = re.search(r'/folders/([a-zA-Z0-9_-]+)', link_or_id)
    return m.group(1) if m else link_or_id.strip()

def list_drive_contents(service, folder_id: str) -> List[Dict]:
    query = f"'{folder_id}' in parents and trashed=false"
    result = service.files().list(
        q=query, fields="files(id,name,mimeType)", supportsAllDrives=True, includeItemsFromAllDrives=True
    ).execute()
    return result.get('files', [])

def find_existing_file(service, file_name: str, parent_folder_id: str) -> str:
    query = f"name='{file_name}' and '{parent_folder_id}' in parents and trashed=false"
    try:
        result = service.files().list(
            q=query, fields="files(id,name)", supportsAllDrives=True, includeItemsFromAllDrives=True
        ).execute()
        files = result.get('files', [])
        return files[0]['id'] if files else None
    except Exception as e:
        print(f"L·ªói khi t√¨m ki·∫øm file: {e}")
        return None

# --- ‚≠ê LOGIC DOWNLOAD T·ªêI ∆ØU M·ªöI ---

def _discover_files_recursive(service, item_id: str, item_name: str, current_path: str, files_to_download: list):
    """
    (H√†m n·ªôi b·ªô) ƒê·ªá quy ƒë·ªÉ kh√°m ph√° t·∫•t c·∫£ c√°c file trong c√¢y th∆∞ m·ª•c.
    """
    # T·∫°o ƒë∆∞·ªùng d·∫´n cho th∆∞ m·ª•c hi·ªán t·∫°i
    folder_path = os.path.join(current_path, item_name)
    os.makedirs(folder_path, exist_ok=True)
    
    # L·∫•y danh s√°ch item con
    sub_items = list_drive_contents(service, item_id)
    for sub_item in sub_items:
        if sub_item['mimeType'] == 'application/vnd.google-apps.folder':
            # N·∫øu l√† th∆∞ m·ª•c, ti·∫øp t·ª•c ƒë·ªá quy
            _discover_files_recursive(service, sub_item['id'], sub_item['name'], folder_path, files_to_download)
        else:
            # N·∫øu l√† file, th√™m v√†o danh s√°ch c·∫ßn t·∫£i
            file_info = {
                'id': sub_item['id'],
                'name': sub_item['name'],
                'save_path': os.path.join(folder_path, sub_item['name'])
            }
            files_to_download.append(file_info)

def _download_worker(service, file_info: Dict) -> str:
    """
    (H√†m n·ªôi b·ªô) Worker ƒë·ªÉ t·∫£i xu·ªëng m·ªôt file duy nh·∫•t.
    """
    file_id = file_info['id']
    save_path = file_info['save_path']
    try:
        request = service.files().get_media(fileId=file_id)
        with open(save_path, 'wb') as f:
            downloader = MediaIoBaseDownload(f, request)
            done = False
            while not done:
                _, done = downloader.next_chunk()
        return f"‚úÖ ƒê√£ t·∫£i xu·ªëng: {save_path}"
    except Exception as e:
        return f"‚ùå L·ªói khi t·∫£i {os.path.basename(save_path)}: {e}"

def download_selected(service, items: List[Dict], download_path: str, max_workers: int = 10) -> List[str]:
    """
    T·∫£i xu·ªëng c√°c file v√† th∆∞ m·ª•c ƒë∆∞·ª£c ch·ªçn v·ªõi hi·ªáu su·∫•t cao.
    """
    files_to_download = []
    
    # B∆∞·ªõc 1: Kh√°m ph√° t·∫•t c·∫£ c√°c file
    for item in items:
        if item['mimeType'] == 'application/vnd.google-apps.folder':
            _discover_files_recursive(service, item['id'], item['name'], download_path, files_to_download)
        else:
            # X·ª≠ l√Ω c√°c file ƒë∆∞·ª£c ch·ªçn ·ªü c·∫•p cao nh·∫•t
            file_info = {
                'id': item['id'],
                'name': item['name'],
                'save_path': os.path.join(download_path, item['name'])
            }
            files_to_download.append(file_info)
    
    if not files_to_download:
        return ["Kh√¥ng c√≥ file n√†o ƒë·ªÉ t·∫£i."]

    log = [f"üîé T√¨m th·∫•y {len(files_to_download)} file. B·∫Øt ƒë·∫ßu t·∫£i xu·ªëng..."]
    
    # B∆∞·ªõc 2: Th·ª±c thi t·∫£i xu·ªëng ƒë·ªìng th·ªùi
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        # T·∫°o m·ªôt partial function ƒë·ªÉ truy·ªÅn 'service' v√†o worker
        from functools import partial
        worker = partial(_download_worker, service)
        
        # G·ª≠i t·∫•t c·∫£ c√°c t√°c v·ª• download v√†o pool v√† thu th·∫≠p k·∫øt qu·∫£
        results = list(executor.map(worker, files_to_download))
        log.extend(results)
            
    return log

# --- H√ÄM UPLOAD GI·ªÆ NGUY√äN NH∆Ø PHI√äN B·∫¢N T·ªêI ∆ØU TR∆Ø·ªöC ---
def upload_files_to_drive(
    service,
    local_file_paths: List[str],
    parent_folder_id: str,
    overwrite: bool = False,
    max_workers: int = 5
) -> List[str]:
    log = []

    def _upload_file(local_path):
        if not os.path.exists(local_path):
            return f"‚ö†Ô∏è B·ªè qua file kh√¥ng t·ªìn t·∫°i: {local_path}"
        
        file_name = os.path.basename(local_path)
        try:
            existing_file_id = None
            if overwrite:
                existing_file_id = find_existing_file(service, file_name, parent_folder_id)

            mimetype = 'video/mp4' if local_path.lower().endswith('.mp4') else None
            media = MediaFileUpload(local_path, mimetype=mimetype, resumable=True)

            if existing_file_id:
                file = service.files().update(
                    fileId=existing_file_id, media_body=media, fields='id, webViewLink', supportsAllDrives=True
                ).execute()
                return f"üîÑ ƒê√£ ghi ƒë√®: {file_name} -> Link: {file.get('webViewLink')}"
            else:
                file_metadata = {'name': file_name, 'parents': [parent_folder_id]}
                file = service.files().create(
                    body=file_metadata, media_body=media, fields='id, webViewLink', supportsAllDrives=True
                ).execute()
                return f"‚úÖ ƒê√£ t·∫£i l√™n: {file_name} -> Link: {file.get('webViewLink')}"
        except Exception as e:
            return f"‚ùå L·ªói khi t·∫£i l√™n {file_name}: {e}"

    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_path = {executor.submit(_upload_file, path): path for path in local_file_paths}
        
        for future in concurrent.futures.as_completed(future_to_path):
            log.append(future.result())
            
    return log